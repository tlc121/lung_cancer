{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread\n",
    "import random\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),   # horizontal flip\n",
    "        transforms.RandomVerticalFlip(),   # vertival flip\n",
    "        #transforms.ColorJitter([0.8,1.3],0.3,0.3,0.3),\n",
    "#         ImageNetPolicy(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]) \n",
    "}\n",
    "\n",
    "def hsv_transform(img, hue_delta, sat_mult, val_mult):\n",
    "        img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.float)\n",
    "        img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_delta) % 180\n",
    "        img_hsv[:, :, 1] *= sat_mult\n",
    "        img_hsv[:, :, 2] *= val_mult\n",
    "        img_hsv[img_hsv > 255] = 255\n",
    "        return cv2.cvtColor(np.round(img_hsv).astype(np.uint8), cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "def random_hsv_transform(img, hue_vari, sat_vari, val_vari):\n",
    "        hue_delta = np.random.randint(-hue_vari, hue_vari)\n",
    "        sat_mult = 1 + np.random.uniform(-sat_vari, sat_vari)\n",
    "        val_mult = 1 + np.random.uniform(-val_vari, val_vari)\n",
    "        return hsv_transform(img, hue_delta, sat_mult, val_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset): #继承Dataset\n",
    "    def __init__(self, folder_name, name, transform=None, train=True):\n",
    "        #self.hospitals = hospitals\n",
    "        self.folder_name = folder_name\n",
    "        self.name = name\n",
    "        path = []    \n",
    "        temp_path = []\n",
    "        #print (len(glob(self.folder_name[0] + '/*/*/*/')))\n",
    "        img_path = glob(self.folder_name[0] + '/*/*/*/*/*.npy')\n",
    "        for j in img_path:\n",
    "            if 'ASC-US' in j or 'ASC-H' in j:\n",
    "                label = 1\n",
    "            elif 'pos' in j:\n",
    "                label = 2\n",
    "            elif 'neg' in j:\n",
    "                label = 0\n",
    "            \n",
    "            if 'CH' in j:\n",
    "                hos = 0\n",
    "            elif 'QL' in j:\n",
    "                hos = 1\n",
    "            elif 'YFY' in j:\n",
    "                hos = 2\n",
    "            elif 'TR' in j:\n",
    "                hos =3\n",
    "            path.append((j,label, hos))\n",
    "                \n",
    "#         torch.save(path,\"/hdd/sd2/data/TCT/densenet/model/0611_more_TRdata_224/path.pth\")\n",
    "        \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        print(len(path),self.name)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path,target, hos = self.path[index] \n",
    "        if target == 0:\n",
    "            target = np.array((0.95,0.05)).astype(np.float32)\n",
    "        elif target == 1:\n",
    "            target = np.array((0.3,0.7)).astype(np.float32)\n",
    "        elif target == 2:\n",
    "            target = np.array((0.05,0.95)).astype(np.float32)\n",
    "        \n",
    "\n",
    "        else:\n",
    "            print(\"one-hot error!\")\n",
    "        #target = np.array((1-target,target)).astype(np.float32)\n",
    "        ori_img = np.load(img_path)\n",
    "        ori_img = random_hsv_transform(ori_img, 10, 0.1, 0.1)\n",
    "        ori_img = cv2.resize(ori_img,(224,224))\n",
    "        sample = Image.fromarray(ori_img) # array to image)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        if self.train:\n",
    "            return sample, target, hos, img_path \n",
    "        else:\n",
    "            return sample, target, hos, img_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs =[\"/ssd2/yuyue/TCT_data/20200701_data/train/\"]\n",
    "val_dirs = [\"/ssd2/yuyue/TCT_data/20200701_data/val/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174569"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob(\"/ssd2/yuyue/TCT_data/20200701_data/train/*/*/*/*/*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174569 train\n",
      "34203 val\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(train_dirs, \"train\", transform=data_transforms[\"train\"])\n",
    "val_dataset = MyDataset(val_dirs, \"val\", transform=data_transforms[\"val\"])\n",
    "# test_dataset = MyDataset(test_dirs,\"test\",transform=data_transforms[\"test\"])\n",
    "\n",
    "image_datasets = {\"train\":train_dataset, \"val\":val_dataset}\n",
    "dataloaders = {\"train\": torch.utils.data.DataLoader(image_datasets[\"train\"], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4),\n",
    "              \"val\":torch.utils.data.DataLoader(image_datasets[\"val\"], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch):\n",
    "    save_dir = \"/hdd/sd5/tlc/TCT/Model_pth/\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    state_dict = model.state_dict()\n",
    "    pth = os.path.join(save_dir, \"DAN_network_weight.pth\")\n",
    "    torch.save(state_dict, pth)\n",
    "\n",
    "def train_model(model, criterion_cls, criterion_domain, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "#     model = DataParallel(model)\n",
    "   # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\",'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "#             count  = 0\n",
    "            for data in dataloaders[phase]:\n",
    "                \n",
    "                # get the inputs\n",
    "                inputs, labels , domains, paths = data\n",
    "#                 print(labels[0].shape)\n",
    "#                 print(labels)\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                    domains = Variable(domains.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs_cls, outputs_domain= model(inputs, 1)\n",
    "#                 outputs = nn.Softmax(dim=-1)(outputs)\n",
    "                \n",
    "    \n",
    "                temp_outputs = torch.tensor([[0.5,0.5]]).cuda()\n",
    "                temp_labels = torch.tensor([[0.5,0.5]]).cuda()\n",
    "            \n",
    "                temp_outputs_2 = torch.tensor([[0.5,0.5]]).cuda()\n",
    "                temp_labels_2 = torch.tensor([[0.5,0.5]]).cuda()\n",
    "            \n",
    "                temp_outputs = temp_outputs.cuda()\n",
    "                temp_labels = temp_labels.cuda()\n",
    "                \n",
    "                \n",
    "                for idx in range(len(labels)):\n",
    "                    if labels[idx][1] == 0.7 and outputs_cls[idx][1] > 0.7:\n",
    "                        temp_outputs_2 = torch.cat((temp_outputs_2,outputs_cls[idx].unsqueeze(0)),0)\n",
    "                        temp_labels_2 = torch.cat((temp_labels_2,labels[idx].unsqueeze(0)),0)\n",
    "                    else:\n",
    "                        temp_outputs = torch.cat((temp_outputs,outputs_cls[idx].unsqueeze(0)),0)\n",
    "                        temp_labels = torch.cat((temp_labels,labels[idx].unsqueeze(0)),0)\n",
    "                \n",
    "                \n",
    "                \n",
    "                _, preds = torch.max(outputs_cls.data, 1) # pred值为output中最大值的位置（0是neg,1是pos）\n",
    "                _, gts = torch.max(labels.data, 1)\n",
    "                \n",
    "#                 print(temp_outputs.shape)\n",
    "#                 print(temp_labels)\n",
    "                loss = criterion_cls(outputs_cls, labels) + 0.1*criterion_cls(temp_outputs_2, temp_labels_2) + 1.0 * criterion_domain(outputs_domain, domains)\n",
    "#                 loss = criterion(outputs,labels)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()* inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == gts)\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss and epoch > 5:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                save_model(model, epoch)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('Best val epoch: {:4f}'.format(best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "\n",
    "model_ft = resnet.resnet18(pretrained =True)\n",
    "model_ft.fc = nn.Linear(model_ft.fc.in_features, 2)\n",
    "\n",
    "\n",
    "# model_ft.load_state_dict(torch.load(\"/hdd/sd2/data/TCT/densenet/model/0604_TRdata_224/resnet18_asc0.8_pos0.95_0.5negweight_resize224_hard_neg_no_aug_2.pth\"))\n",
    "model_ft.cuda()    \n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "#weight=torch.Tensor([[1,1]]).cuda()\n",
    "# criterion = FocalLoss() \n",
    "w = torch.Tensor([0.5,0.5]).cuda()\n",
    "criterion_cls = nn.BCELoss(w)\n",
    "criterion_domain = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "# do not forget to change learning rate\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-4, momentum=0.9,weight_decay=1e-4)\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=1e-4,weight_decay=1e-4)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.5)\n",
    "# exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=5, eta_min=1e-6, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6705 Acc: 0.7755\n",
      "val Loss: 1.5838 Acc: 0.8791\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.5249 Acc: 0.8549\n",
      "val Loss: 1.5775 Acc: 0.9026\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.5014 Acc: 0.8993\n",
      "val Loss: 1.5812 Acc: 0.9021\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.4920 Acc: 0.9156\n",
      "val Loss: 1.6001 Acc: 0.8745\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.4866 Acc: 0.9261\n",
      "val Loss: 1.5930 Acc: 0.8874\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.4775 Acc: 0.9408\n",
      "val Loss: 1.5785 Acc: 0.9064\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.4740 Acc: 0.9469\n",
      "val Loss: 1.5788 Acc: 0.9103\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.4720 Acc: 0.9502\n",
      "val Loss: 1.5841 Acc: 0.8960\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.4672 Acc: 0.9583\n",
      "val Loss: 1.5808 Acc: 0.9073\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.4654 Acc: 0.9615\n",
      "val Loss: 1.5845 Acc: 0.9014\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.4638 Acc: 0.9639\n",
      "val Loss: 1.5864 Acc: 0.9005\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.4614 Acc: 0.9679\n",
      "val Loss: 1.5896 Acc: 0.8947\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.4602 Acc: 0.9703\n",
      "val Loss: 1.5826 Acc: 0.9034\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.4596 Acc: 0.9714\n",
      "val Loss: 1.5865 Acc: 0.9009\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.4580 Acc: 0.9736\n",
      "val Loss: 1.5883 Acc: 0.8972\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.4575 Acc: 0.9743\n",
      "val Loss: 1.5813 Acc: 0.9061\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.4572 Acc: 0.9753\n",
      "val Loss: 1.5861 Acc: 0.8985\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.4563 Acc: 0.9762\n",
      "val Loss: 1.5851 Acc: 0.9016\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.4562 Acc: 0.9765\n",
      "val Loss: 1.5833 Acc: 0.9028\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.4560 Acc: 0.9769\n",
      "val Loss: 1.5858 Acc: 0.9023\n",
      "Training complete in 140m 25s\n",
      "Best val Loss: 1.578832\n",
      "Best val epoch: 6.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion_cls, criterion_domain, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
