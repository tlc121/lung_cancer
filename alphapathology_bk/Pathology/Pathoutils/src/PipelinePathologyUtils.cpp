//
//
//  Generated by StarUML(tm) C++ Add-In
//
//  @ Project : Utils
//  @ File Name : PipelinePathologyUtils.cpp
//  @ Date : 2019/8/15
//  @ Author : weiping liu
//
//


#include "PipelinePathologyUtils.h"
#include "IFPipelinePathologyUtilsOut.h"
#include "PipelineElementPathologyUtilsCls.h"
#include "CommonUtils.h"
#include "IFPipelinePathologyUtilsIn.h"
#include "tensorflow/cc/ops/image_ops.h"
#include "tensorflow/cc/ops/standard_ops.h"
#include "tensorflow/core/framework/graph.pb.h"
#include "tensorflow/core/framework/tensor.h"
#include "tensorflow/core/graph/default_device.h"
#include "tensorflow/core/graph/graph_def_builder.h"
#include "tensorflow/core/platform/logging.h"
#include "tensorflow/core/platform/types.h"
#include "tensorflow/core/public/session.h"

class tensorflow_operator
{
public:
	tensorflow::Session* session_tct;
	tensorflow::Session* session_rose;
};

namespace ALPHA
{
	namespace Pathology 
	{
		namespace PTUtils
		{
			PipelinePathologyUtils::PipelinePathologyUtils()
			{}

			PipelinePathologyUtils::PipelinePathologyUtils(std::string config_path, std::string task_type) :COMM::PipelineAlgorithmExecutor(),
				ptrPipelineIn(nullptr), ptrPipelineOut(nullptr)
			{
				m_operator = new tensorflow_operator;
				this->m_config_path = config_path;
				this->m_task = task_type;
			}



			PipelinePathologyUtils::~PipelinePathologyUtils()
			{
				if (m_operator != NULL)
					delete m_operator;
			}


			void PipelinePathologyUtils::read_tct_model() {
				libconfig::Config mConfig;
				ALPHA::COMM::loadCfg(this->m_config_path, mConfig);
				std::string graph_path = mConfig.lookup("PT_UTILS.MODEL_TCT_PATH"); //model path
				float gpu_ratio = mConfig.lookup("PT_UTILS.TCT_GPU_RATIO");
				tensorflow::GraphDef graph_def;
				if (!ReadBinaryProto(tensorflow::Env::Default(), graph_path, &graph_def).ok())
				{
					std::cout << "load .pb failed, Plz check the path" << std::endl;
				}
				else
				{
					std::cout << "load model successfully!" << std::endl;
				}

				tensorflow::SessionOptions sess_opt;
				sess_opt.config.mutable_gpu_options()->set_allow_growth(false);
				sess_opt.config.mutable_gpu_options()->set_per_process_gpu_memory_fraction(gpu_ratio);
				m_operator->session_tct = tensorflow::NewSession(sess_opt);
				std::cout << "Create graph" << std::endl;
				if (!m_operator->session_tct->Create(graph_def).ok()) {
					std::cout << "Create graph failed" << std::endl;
				}
			}

			void PipelinePathologyUtils::read_rose_model() {
				libconfig::Config mConfig;
				ALPHA::COMM::loadCfg(this->m_config_path, mConfig);
				std::string graph_path = mConfig.lookup("PT_UTILS.MODEL_ROSE_PATH"); //model path
				float gpu_ratio = mConfig.lookup("PT_UTILS.ROSE_GPU_RATIO");
				tensorflow::GraphDef graph_def;
				if (!ReadBinaryProto(tensorflow::Env::Default(), graph_path, &graph_def).ok())
				{
					std::cout << "load .pb failed, Plz check the path" << std::endl;
				}
				else
				{
					std::cout << "load model successfully!" << std::endl;
				}

				tensorflow::SessionOptions sess_opt;
				sess_opt.config.mutable_gpu_options()->set_allow_growth(false);
				sess_opt.config.mutable_gpu_options()->set_per_process_gpu_memory_fraction(gpu_ratio);
				m_operator->session_rose = tensorflow::NewSession(sess_opt);
				std::cout << "Create graph" << std::endl;
				if (!m_operator->session_rose->Create(graph_def).ok()) {
					std::cout << "Create graph failed" << std::endl;
				}
			}

			void PipelinePathologyUtils::setUpPipeline()
			{
				//std::cout << "PipelineHemorrhagicStroke::setUpPipeline()" << std::endl;
				LOG4CPLUS_INFO(COMM::MyLogger::getInstance()->m_rootLog, "PipelinePathologyUtils::setUpPipeline()!");

				// step 1: classification
				std::shared_ptr<PTUtils::PipelineElementPathologyUtilsCls>
					ptrPipelineElementPathologyUtilsCls(new PipelineElementPathologyUtilsCls());
				if (this->m_task == "TCT")
					ptrPipelineElementPathologyUtilsCls->m_sesssion = m_operator->session_tct;
				else if (this->m_task == "ROSE")
					ptrPipelineElementPathologyUtilsCls->m_sesssion = m_operator->session_rose;
				listElement.push_back(ptrPipelineElementPathologyUtilsCls);

			}


			void PipelinePathologyUtils::executePipeline()
			{
				//std::cout << "PipelineHemorrhagicStroke::executePipeline()" << std::endl;
				//std::list<std::shared_ptr<PipelineElementBase>> listElement;
				std::list<std::shared_ptr<COMM::PipelineElementBase>>::iterator
					itPre = listElement.begin();
				auto itCurr = itPre;
				if (itCurr != listElement.end())
				{
					++itCurr;
				}
				else
				{
					LOG4CPLUS_ERROR(COMM::MyLogger::getInstance()->m_rootLog, "PipelinePathologyUtils need at least one algorithmElement! Quite pipeline computation!");
					return;
				}
				if (ptrPipelineIn == nullptr)
				{
					LOG4CPLUS_ERROR(COMM::MyLogger::getInstance()->m_rootLog, "nullptr input in PipelinePathologyUtils! Quite pipeline computation!");
					return;
				}
				(*itPre)->setInput(ptrPipelineIn);
				for (; itCurr != listElement.end(); ++itCurr, ++itPre)
				{
					(*itPre)->update();
					(*itCurr)->setInput((*itPre)->getOutput());
				}
				(*itPre)->update();
				this->ptrPipelineOut = std::dynamic_pointer_cast<IFPipelinePathologyUtilsOut>((*itPre)->getOutput());
			}

			void PipelinePathologyUtils::setInput(std::shared_ptr<COMM::DataObj> Input)
			{
				ptrPipelineIn = std::dynamic_pointer_cast<PTUtils::IFPipelinePathologyUtilsIn>(Input);
			}

			std::shared_ptr<COMM::DataObj> PipelinePathologyUtils::getOutput()
			{
				//TO DO: need to edit for the output

				return ptrPipelineOut;
			}
		}
	}
}